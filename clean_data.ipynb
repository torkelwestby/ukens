{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d4195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA = Path(\"data\")\n",
    "OUT = Path(\"data/clean\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def normalize_orgnr(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str).str.replace(r\"\\D\", \"\", regex=True).str[-9:]\n",
    "    return s.where(s.str.len() == 9)\n",
    "\n",
    "# --- HubSpot ---\n",
    "HUBSPOT_KEEP = {\n",
    "    \"Company name\": \"company_name\",\n",
    "    \"Organisasjonsnummer\": \"orgnr\",\n",
    "    \"Last Activity Date\": \"last_activity_date\",\n",
    "    \"Record ID\": \"record_id\",\n",
    "}\n",
    "\n",
    "hs = pd.read_csv(DATA / \"hubspot.csv\", dtype=\"string\")\n",
    "hs = hs.rename(columns=HUBSPOT_KEEP)\n",
    "hs = hs[[c for c in HUBSPOT_KEEP.values() if c in hs.columns]]\n",
    "if \"orgnr\" in hs:\n",
    "    hs[\"orgnr\"] = normalize_orgnr(hs[\"orgnr\"])\n",
    "if \"company_name\" in hs:\n",
    "    hs[\"company_name\"] = hs[\"company_name\"].astype(str).str.strip()\n",
    "if \"last_activity_date\" in hs:\n",
    "    hs[\"last_activity_date\"] = pd.to_datetime(hs[\"last_activity_date\"], errors=\"coerce\")\n",
    "\n",
    "hs.to_parquet(OUT / \"hubspot_clean.parquet\", index=False)\n",
    "\n",
    "# --- Brønnøysund ---\n",
    "BRREG_KEEP = {\n",
    "    \"navn\": \"company_name\",\n",
    "    \"organisasjonsnummer\": \"orgnr\",\n",
    "    \"naeringskode1.kode\": \"nace\",\n",
    "    \"antallAnsatte\": \"employees\",\n",
    "}\n",
    "\n",
    "header = pd.read_csv(DATA / \"brreg.csv\", nrows=0).columns.tolist()\n",
    "usecols = [c for c in BRREG_KEEP.keys() if c in header]\n",
    "\n",
    "chunks = pd.read_csv(\n",
    "    DATA / \"brreg.csv\",\n",
    "    usecols=usecols,\n",
    "    dtype=\"string\",\n",
    "    chunksize=200_000,\n",
    "    low_memory=True,\n",
    ")\n",
    "\n",
    "parts = []\n",
    "for ch in chunks:\n",
    "    ch = ch.rename(columns=BRREG_KEEP)\n",
    "    if \"orgnr\" in ch:\n",
    "        ch[\"orgnr\"] = normalize_orgnr(ch[\"orgnr\"])\n",
    "    if \"company_name\" in ch:\n",
    "        ch[\"company_name\"] = ch[\"company_name\"].astype(str).str.strip()\n",
    "    parts.append(ch)\n",
    "\n",
    "br = pd.concat(parts, ignore_index=True)\n",
    "br.to_parquet(OUT / \"brreg_clean.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad00fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import math, gzip\n",
    "import pandas as pd\n",
    "\n",
    "DATA = Path(\"data\")\n",
    "OUT = Path(\"data/clean\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- felles ---\n",
    "def normalize_orgnr(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str).str.replace(r\"\\D\", \"\", regex=True).str[-9:]\n",
    "    return s.where(s.str.len()==9)\n",
    "\n",
    "# hvilke kolonner fra brreg.csv vi beholder\n",
    "BRREG_KEEP = {\n",
    "    \"navn\": \"company_name\",\n",
    "    \"organisasjonsnummer\": \"orgnr\",\n",
    "    \"naeringskode1.kode\": \"nace\",\n",
    "    \"antallAnsatte\": \"employees\",\n",
    "}\n",
    "\n",
    "# les header for å tåle manglende kolonner\n",
    "hdr = pd.read_csv(DATA/\"brreg.csv\", nrows=0).columns.tolist()\n",
    "usecols = [c for c in BRREG_KEEP.keys() if c in hdr]\n",
    "\n",
    "# strøm inn og rens\n",
    "parts = []\n",
    "for ch in pd.read_csv(\n",
    "    DATA/\"brreg.csv\",\n",
    "    usecols=usecols,\n",
    "    dtype=\"string\",\n",
    "    chunksize=200_000,\n",
    "    low_memory=True,\n",
    "):\n",
    "    ch = ch.rename(columns=BRREG_KEEP)\n",
    "    if \"orgnr\" in ch: ch[\"orgnr\"] = normalize_orgnr(ch[\"orgnr\"])\n",
    "    if \"company_name\" in ch: ch[\"company_name\"] = ch[\"company_name\"].astype(str).str.strip()\n",
    "    parts.append(ch)\n",
    "\n",
    "df = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "# dedup på orgnr, ellers navn\n",
    "if \"orgnr\" in df:\n",
    "    df = pd.concat([\n",
    "        df[df[\"orgnr\"].notna()].drop_duplicates(\"orgnr\", keep=\"first\"),\n",
    "        df[df[\"orgnr\"].isna()].drop_duplicates(\"company_name\", keep=\"first\"),\n",
    "    ], ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# ALTERNATIV A: Parquet sharding\n",
    "# -----------------------------\n",
    "# Velg antall shards. Øk til filene < 100 MB.\n",
    "SHARDS = 12\n",
    "shard_dir = OUT / \"brreg_parquet_shards\"\n",
    "shard_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# nøkkel for sharding\n",
    "key = df[\"orgnr\"].fillna(df[\"company_name\"]).astype(str)\n",
    "bucket = key.apply(lambda x: hash(x) % SHARDS)\n",
    "for b in range(SHARDS):\n",
    "    part = df[bucket == b]\n",
    "    if len(part) == 0:\n",
    "        continue\n",
    "    outp = shard_dir / f\"brreg_clean.part{b:02d}.parquet\"\n",
    "    part.to_parquet(outp, index=False)\n",
    "\n",
    "# Eksempel på lesing i app:\n",
    "# import glob, pandas as pd\n",
    "# files = sorted(glob.glob(\"data/clean/brreg_parquet_shards/*.parquet\"))\n",
    "# df_br = pd.concat((pd.read_parquet(f) for f in files), ignore_index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
